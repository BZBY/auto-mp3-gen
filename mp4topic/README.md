# è§†é¢‘å…³é”®å¸§æå–å™¨ (Video KeyFrame Extractor)

ä¸€ä¸ªå…ˆè¿›çš„æ¨¡å—åŒ–è§†é¢‘å…³é”®å¸§æå–å·¥å…·ï¼Œé›†æˆäº†TransNetV2é•œå¤´æ£€æµ‹ã€CLIPè¯­ä¹‰ç‰¹å¾æå–ã€å…‰æµè¿åŠ¨åˆ†æå’Œæ™ºèƒ½èšç±»ç®—æ³•ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ¯ **æ™ºèƒ½é•œå¤´æ£€æµ‹**: æ”¯æŒTransNetV2ç¥ç»ç½‘ç»œå’Œå¤šç§å¤‡ç”¨ç®—æ³•
- ğŸ§  **CLIPè¯­ä¹‰ç‰¹å¾**: ä½¿ç”¨OpenAI CLIPæ¨¡å‹æå–è§†è§‰è¯­ä¹‰ç‰¹å¾
- ğŸ”„ **å…‰æµè¿åŠ¨åˆ†æ**: åŸºäºå¯†é›†å…‰æµçš„è¿åŠ¨ç‰¹å¾æå–
- ğŸ“Š **è‡ªé€‚åº”èšç±»**: DBSCANèšç±»ç®—æ³•è‡ªåŠ¨é€‰æ‹©ä»£è¡¨æ€§å…³é”®å¸§
- ğŸ”§ **æ¨¡å—åŒ–è®¾è®¡**: æ¾è€¦åˆçš„ç»„ä»¶è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œå®šåˆ¶
- âš™ï¸ **çµæ´»é…ç½®**: ä¸°å¯Œçš„é…ç½®é€‰é¡¹å’Œé¢„è®¾æ¨¡å¼
- ğŸ“ **å®Œæ•´è¾“å‡º**: å›¾åƒã€å…ƒæ•°æ®ã€CSVå’Œè¯¦ç»†æŠ¥å‘Š

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…CLIPæ¨¡å‹
pip install git+https://github.com/openai/CLIP.git

# å¯é€‰ï¼šå®‰è£…TransNetV2ï¼ˆæ¨èï¼Œç”¨äºæ›´å¥½çš„é•œå¤´æ£€æµ‹ï¼‰
pip install transnetv2 tensorflow
```

### æ¨¡å‹å­˜å‚¨é…ç½®

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹æ–‡ä»¶å°†ä¸‹è½½åˆ°é¡¹ç›®ç›®å½•ä¸‹çš„ `models` æ–‡ä»¶å¤¹ä¸­ï¼Œé¿å…å ç”¨Cç›˜ç©ºé—´ï¼š

```
é¡¹ç›®ç›®å½•/
â”œâ”€â”€ models/                    # æ¨¡å‹å­˜å‚¨ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â”œâ”€â”€ clip/                 # CLIPæ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ transnetv2/          # TransNetV2æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ torch/               # PyTorchæ¨¡å‹ç¼“å­˜
â”‚   â””â”€â”€ tfhub/               # TensorFlow Hubç¼“å­˜
â”œâ”€â”€ src/
â””â”€â”€ main.py
```

#### è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®

å¦‚æœéœ€è¦è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ä½ç½®ï¼š

```python
# æ–¹æ³•1ï¼šé€šè¿‡é…ç½®è®¾ç½®
config = Config(models_dir="/path/to/your/models")

# æ–¹æ³•2ï¼šé€šè¿‡å‘½ä»¤è¡Œå‚æ•°
python main.py video.mp4 --models-dir /path/to/your/models

# æ–¹æ³•3ï¼šä½¿ç”¨æ¨¡å‹ç®¡ç†å·¥å…·
python model_manager.py setup --directory /path/to/your/models
```

### åŸºæœ¬ä½¿ç”¨

```python
from video_keyframe_extractor import KeyFrameExtractor

# ä½¿ç”¨é»˜è®¤é…ç½®
extractor = KeyFrameExtractor()
extractor.initialize()

# æå–å…³é”®å¸§
results = extractor.extract_keyframes("video.mp4", "output_dir")

# æ¸…ç†èµ„æº
extractor.cleanup()

print(f"æå–äº† {len(results)} ä¸ªå…³é”®å¸§")
```

### ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆæ¨èï¼‰

```python
from video_keyframe_extractor import KeyFrameExtractor

with KeyFrameExtractor() as extractor:
    results = extractor.extract_keyframes("video.mp4", "output_dir")
    print(f"æå–äº† {len(results)} ä¸ªå…³é”®å¸§")
```

## ğŸ“‹ é…ç½®é€‰é¡¹

### é¢„è®¾é…ç½®

```python
from video_keyframe_extractor.core.config import ConfigManager

config_manager = ConfigManager()

# å¯ç”¨é¢„è®¾ï¼šfast, balanced, quality, detailed
config = config_manager.create_preset_config("balanced")

with KeyFrameExtractor(config) as extractor:
    results = extractor.extract_keyframes("video.mp4", "output")
```

### è‡ªå®šä¹‰é…ç½®

```python
from video_keyframe_extractor import Config

config = Config(
    target_fps=15,                    # ç›®æ ‡é‡‡æ ·å¸§ç‡
    similarity_threshold=0.95,        # ç›¸ä¼¼åº¦å»é‡é˜ˆå€¼
    max_keyframes_per_shot=5,         # æ¯ä¸ªé•œå¤´æœ€å¤§å…³é”®å¸§æ•°
    use_transnet=True,                # ä½¿ç”¨TransNetV2
    output_resolution=(768, 768),     # è¾“å‡ºå›¾åƒåˆ†è¾¨ç‡
    image_quality=95                  # JPEGè´¨é‡
)
```

### é…ç½®æ–‡ä»¶

```python
# ä¿å­˜é…ç½®
config.save_to_file("my_config.json")

# åŠ è½½é…ç½®
config = Config.from_file("my_config.json")
```

## ğŸ› ï¸ æ¨¡å‹ç®¡ç†å·¥å…·

é¡¹ç›®æä¾›äº†ä¸“é—¨çš„æ¨¡å‹ç®¡ç†å·¥å…·ï¼Œæ–¹ä¾¿ç®¡ç†æ¨¡å‹æ–‡ä»¶ï¼š

### æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯

```bash
# æŸ¥çœ‹æ¨¡å‹çŠ¶æ€å’Œå­˜å‚¨ä¿¡æ¯
python model_manager.py info

# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹ç›®å½•
python model_manager.py info --models-dir /path/to/models
```

### é¢„ä¸‹è½½æ¨¡å‹

```bash
# ä¸‹è½½æ‰€æœ‰æ¨¡å‹
python model_manager.py download --all

# ä»…ä¸‹è½½CLIPæ¨¡å‹
python model_manager.py download --clip

# ä»…ä¸‹è½½TransNetV2æ¨¡å‹
python model_manager.py download --transnet
```

### æ¸…ç†æ¨¡å‹ç¼“å­˜

```bash
# æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜
python model_manager.py clean --confirm

# æ¸…ç†ç‰¹å®šæ¨¡å‹ç¼“å­˜
python model_manager.py clean --type clip --confirm
```

### è®¾ç½®è‡ªå®šä¹‰æ¨¡å‹ç›®å½•

```bash
# è®¾ç½®è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨ç›®å½•
python model_manager.py setup --directory /path/to/your/models
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### æ‰¹é‡å¤„ç†

```python
video_paths = ["video1.mp4", "video2.mp4", "video3.mp4"]

with KeyFrameExtractor() as extractor:
    results = extractor.extract_keyframes_batch(video_paths, "batch_output")

    for video_path, video_results in results.items():
        print(f"{video_path}: {len(video_results)} å…³é”®å¸§")
```

### è§†é¢‘è‡ªé€‚åº”é…ç½®

```python
from video_keyframe_extractor.core.config import ConfigManager

config_manager = ConfigManager()

# æ ¹æ®è§†é¢‘ç‰¹æ€§è‡ªåŠ¨ä¼˜åŒ–é…ç½®
optimized_config = config_manager.optimize_for_video("video.mp4")

with KeyFrameExtractor(optimized_config) as extractor:
    results = extractor.extract_keyframes("video.mp4", "output")
```

### ç‰¹å¾åˆ†æ

```python
with KeyFrameExtractor() as extractor:
    # ä»…æå–ç‰¹å¾è€Œä¸ä¿å­˜å…³é”®å¸§
    feature_data = extractor.feature_extractor.extract_all_features("video.mp4")

    # è·å–ç‰¹å¾æ‘˜è¦
    summary = extractor.feature_extractor.get_feature_summary(feature_data)
    print(f"è¿åŠ¨ç‰¹å¾ç»Ÿè®¡: {summary['motion_features']}")
```

## ğŸ“ è¾“å‡ºæ ¼å¼

### æ–‡ä»¶ç»“æ„

```
output_dir/
â”œâ”€â”€ video_shot00_keyframe_0001_frame_000123_1.50s.jpg
â”œâ”€â”€ video_shot00_keyframe_0002_frame_000456_4.20s.jpg
â”œâ”€â”€ video_shot01_keyframe_0003_frame_000789_7.80s.jpg
â”œâ”€â”€ video_metadata.json          # è¯¦ç»†å…ƒæ•°æ®
â”œâ”€â”€ video_keyframes.csv          # CSVæ ¼å¼æ•°æ®
â””â”€â”€ video_summary.txt            # æ–‡æœ¬æ‘˜è¦æŠ¥å‘Š
```

### å…ƒæ•°æ®æ ¼å¼

```json
{
    "video_info": {
        "path": "video.mp4",
        "name": "video"
    },
    "total_keyframes": 15,
    "keyframes": [
        {
            "filename": "video_shot00_keyframe_0001.jpg",
            "frame_idx": 123,
            "timestamp": 1.50,
            "shot_id": 0,
            "confidence": 0.95,
            "selection_method": "cluster_center"
        }
    ]
}
```

## ğŸ›ï¸ é…ç½®å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `target_fps` | int | 10 | ç›®æ ‡é‡‡æ ·å¸§ç‡ |
| `similarity_threshold` | float | 0.9 | ç›¸ä¼¼åº¦å»é‡é˜ˆå€¼ (0-1) |
| `max_keyframes_per_shot` | int | 5 | æ¯ä¸ªé•œå¤´æœ€å¤§å…³é”®å¸§æ•° |
| `use_transnet` | bool | True | æ˜¯å¦ä½¿ç”¨TransNetV2 |
| `cluster_eps` | float | 0.15 | DBSCANèšç±»å‚æ•° |
| `output_resolution` | tuple | (512, 512) | è¾“å‡ºå›¾åƒåˆ†è¾¨ç‡ |
| `image_quality` | int | 95 | JPEGå›¾åƒè´¨é‡ (1-100) |

## ğŸ“– ç¤ºä¾‹ä»£ç 

å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹è¯·å‚è€ƒï¼š

- [`examples/basic_usage.py`](examples/basic_usage.py) - åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
- [`examples/advanced_usage.py`](examples/advanced_usage.py) - é«˜çº§åŠŸèƒ½ç¤ºä¾‹

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
video_keyframe_extractor/
â”œâ”€â”€ core/                    # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ config.py           # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ extractor.py        # ä¸»æå–å™¨
â”œâ”€â”€ models/                  # æ¨¡å‹ç®¡ç†
â”‚   â””â”€â”€ model_manager.py    # CLIPå’ŒTransNetV2ç®¡ç†
â”œâ”€â”€ processors/              # å¤„ç†å™¨æ¨¡å—
â”‚   â”œâ”€â”€ shot_detector.py    # é•œå¤´æ£€æµ‹
â”‚   â”œâ”€â”€ feature_extractor.py# ç‰¹å¾æå–
â”‚   â””â”€â”€ keyframe_selector.py# å…³é”®å¸§é€‰æ‹©
â””â”€â”€ utils/                   # å·¥å…·æ¨¡å—
    â””â”€â”€ output_manager.py   # è¾“å‡ºç®¡ç†
```

## ğŸ”¬ ç®—æ³•åŸç†

### 1. é•œå¤´æ£€æµ‹
- **TransNetV2**: æ·±åº¦å­¦ä¹ ç½‘ç»œï¼Œä¸“é—¨ç”¨äºé•œå¤´è¾¹ç•Œæ£€æµ‹
- **ç›´æ–¹å›¾å·®å¼‚**: åŸºäºHSVé¢œè‰²ç›´æ–¹å›¾çš„ä¼ ç»Ÿæ–¹æ³•
- **å…‰æµåˆ†æ**: åŸºäºè¿åŠ¨å˜åŒ–çš„æ£€æµ‹æ–¹æ³•

### 2. ç‰¹å¾æå–
- **CLIPç‰¹å¾**: 512ç»´è¯­ä¹‰ç‰¹å¾å‘é‡ï¼Œæ•æ‰è§†è§‰å†…å®¹çš„è¯­ä¹‰ä¿¡æ¯
- **è¿åŠ¨ç‰¹å¾**: åŸºäºå¯†é›†å…‰æµçš„è¿åŠ¨å¼ºåº¦åˆ†æ
- **é¢œè‰²ç‰¹å¾**: HSVé¢œè‰²ç›´æ–¹å›¾ç‰¹å¾

### 3. å…³é”®å¸§é€‰æ‹©
- **å€™é€‰å¸§é€‰æ‹©**: è¿åŠ¨å³°å€¼ã€é•œå¤´è¾¹ç•Œã€æ—¶é—´åˆ†å‰²ç‚¹
- **DBSCANèšç±»**: åŸºäºCLIPç‰¹å¾çš„è‡ªé€‚åº”èšç±»
- **ä»£è¡¨å¸§é€‰æ‹©**: é€‰æ‹©æœ€æ¥è¿‘èšç±»ä¸­å¿ƒçš„å¸§
- **å…¨å±€å»é‡**: åŸºäºç›¸ä¼¼åº¦é˜ˆå€¼çš„é‡å¤å¸§è¿‡æ»¤

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ä½¿ç”¨
- æ‰¹é‡å¤„ç†CLIPç‰¹å¾æå–
- åˆ†æ®µåŠ è½½å¤§è§†é¢‘æ–‡ä»¶
- åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„æ•°æ®

### å¤„ç†é€Ÿåº¦
- å¤šç§é‡‡æ ·ç­–ç•¥å‡å°‘å¤„ç†å¸§æ•°
- å¹¶è¡ŒåŒ–ç‰¹å¾è®¡ç®—
- é¢„è®¾é…ç½®å¿«é€Ÿå¯åŠ¨

### ç²¾åº¦å¹³è¡¡
- åŠ¨æ€è°ƒæ•´èšç±»å‚æ•°
- è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—
- å¤šå±‚æ¬¡ç‰¹å¾èåˆ

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CLIPæ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   pip install git+https://github.com/openai/CLIP.git
   ```

2. **TransNetV2ä¸å¯ç”¨**
   ```bash
   pip install transnetv2 tensorflow
   ```

3. **å†…å­˜ä¸è¶³**
   - é™ä½`target_fps`
   - å‡å°`output_resolution`
   - ä½¿ç”¨"fast"é¢„è®¾é…ç½®

4. **GPUæ”¯æŒ**
   - ç¡®ä¿å®‰è£…äº†CUDAç‰ˆæœ¬çš„PyTorch
   - è®¾ç½®`device="cuda"`

### æ—¥å¿—è°ƒè¯•

```python
config = Config(
    verbose=True,
    log_level="DEBUG"
)
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [OpenAI CLIP](https://github.com/openai/CLIP) - è¯­ä¹‰ç‰¹å¾æå–
- [TransNetV2](https://github.com/soCzech/TransNetV2) - é•œå¤´è¾¹ç•Œæ£€æµ‹
- [OpenCV](https://opencv.org/) - å›¾åƒå¤„ç†
- [scikit-learn](https://scikit-learn.org/) - æœºå™¨å­¦ä¹ ç®—æ³•

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»ç»´æŠ¤è€…ã€‚

---

**äº«å—æ™ºèƒ½çš„è§†é¢‘å…³é”®å¸§æå–ï¼** ğŸ¬âœ¨