#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•œå¤´æµ‹è¯•ç»“æœåˆ†æè„šæœ¬
åˆ†æä¸åŒé…ç½®çš„æµ‹è¯•ç»“æœ
"""

import os
import json
import csv
from pathlib import Path
from typing import List, Dict, Any


def analyze_directory(test_dir: Path) -> Dict[str, Any]:
    """åˆ†æå•ä¸ªæµ‹è¯•ç›®å½•çš„ç»“æœ"""
    result = {
        "name": test_dir.name,
        "keyframes_count": 0,
        "shots_covered": 0,
        "avg_confidence": 0,
        "file_size_mb": 0,
        "metadata": None
    }
    
    try:
        # ç»Ÿè®¡å…³é”®å¸§å›¾ç‰‡æ•°é‡
        jpg_files = list(test_dir.glob("*.jpg"))
        result["keyframes_count"] = len(jpg_files)
        
        # è®¡ç®—æ€»æ–‡ä»¶å¤§å°
        total_size = sum(f.stat().st_size for f in jpg_files)
        result["file_size_mb"] = round(total_size / 1024 / 1024, 2)
        
        # è¯»å–å…ƒæ•°æ®
        metadata_file = test_dir / "metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                result["metadata"] = metadata
                
                # æå–ç»Ÿè®¡ä¿¡æ¯
                if "keyframes" in metadata:
                    keyframes = metadata["keyframes"]
                    if keyframes:
                        result["shots_covered"] = len(set(kf.get("shot_id", 0) for kf in keyframes))
                        confidences = [kf.get("confidence", 0) for kf in keyframes]
                        result["avg_confidence"] = round(sum(confidences) / len(confidences), 3)
        
        # è¯»å–CSVæ–‡ä»¶
        csv_file = test_dir / "keyframes.csv"
        if csv_file.exists() and not result["shots_covered"]:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
                if rows:
                    result["shots_covered"] = len(set(row.get("shot_id", "0") for row in rows))
                    if not result["avg_confidence"]:
                        confidences = [float(row.get("confidence", 0)) for row in rows if row.get("confidence")]
                        if confidences:
                            result["avg_confidence"] = round(sum(confidences) / len(confidences), 3)
    
    except Exception as e:
        result["error"] = str(e)
    
    return result


def generate_comparison_report(results: List[Dict[str, Any]], output_file: str):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = [r for r in results if r["keyframes_count"] > 0]
    valid_results.sort(key=lambda x: x["keyframes_count"], reverse=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# é•œå¤´å‚æ•°æµ‹è¯•ç»“æœåˆ†æ\n\n")
        f.write(f"**åˆ†ææ—¶é—´**: {Path().absolute()}\n\n")
        
        # ç»“æœå¯¹æ¯”è¡¨
        f.write("## ğŸ“Š ç»“æœå¯¹æ¯”\n\n")
        f.write("| æµ‹è¯•åç§° | å…³é”®å¸§æ•° | é•œå¤´è¦†ç›– | å¹³å‡ç½®ä¿¡åº¦ | æ–‡ä»¶å¤§å°(MB) | æ•ˆç‡è¯„åˆ†* |\n")
        f.write("|---------|----------|----------|------------|-------------|----------|\n")
        
        for result in valid_results:
            # è®¡ç®—æ•ˆç‡è¯„åˆ† (å…³é”®å¸§æ•° Ã— ç½®ä¿¡åº¦ / å¤„ç†æ—¶é—´çš„è¿‘ä¼¼)
            efficiency = result["keyframes_count"] * result["avg_confidence"] if result["avg_confidence"] else 0
            
            f.write(f"| {result['name']} | {result['keyframes_count']} | "
                   f"{result['shots_covered']} | {result['avg_confidence']} | "
                   f"{result['file_size_mb']} | {efficiency:.1f} |\n")
        
        f.write("\n*æ•ˆç‡è¯„åˆ† = å…³é”®å¸§æ•° Ã— å¹³å‡ç½®ä¿¡åº¦\n\n")
        
        # æœ€ä½³é…ç½®æ¨è
        if valid_results:
            best_count = valid_results[0]  # å…³é”®å¸§æ•°æœ€å¤š
            best_confidence = max(valid_results, key=lambda x: x["avg_confidence"])
            best_efficiency = max(valid_results, key=lambda x: x["keyframes_count"] * x["avg_confidence"])
            
            f.write("## ğŸ† æ¨èé…ç½®\n\n")
            f.write(f"### å…³é”®å¸§æ•°é‡æœ€å¤š\n")
            f.write(f"- **{best_count['name']}**: {best_count['keyframes_count']}ä¸ªå…³é”®å¸§\n\n")
            
            f.write(f"### ç½®ä¿¡åº¦æœ€é«˜\n") 
            f.write(f"- **{best_confidence['name']}**: å¹³å‡ç½®ä¿¡åº¦{best_confidence['avg_confidence']}\n\n")
            
            f.write(f"### ç»¼åˆæ•ˆç‡æœ€ä½³\n")
            f.write(f"- **{best_efficiency['name']}**: æ•ˆç‡è¯„åˆ†{best_efficiency['keyframes_count'] * best_efficiency['avg_confidence']:.1f}\n\n")
        
        # å‚æ•°å½±å“åˆ†æ
        f.write("## ğŸ” å‚æ•°å½±å“åˆ†æ\n\n")
        
        # åˆ†ææœ€å°é•œå¤´é•¿åº¦å½±å“
        min_shot_results = [r for r in valid_results if 'short' in r['name'] or 'long' in r['name'] or 'baseline' in r['name']]
        if len(min_shot_results) >= 2:
            f.write("### é•œå¤´é•¿åº¦è®¾ç½®å½±å“\n")
            for r in min_shot_results:
                f.write(f"- **{r['name']}**: {r['keyframes_count']}ä¸ªå…³é”®å¸§, {r['shots_covered']}ä¸ªé•œå¤´\n")
            f.write("\n")
        
        # åˆ†æç›¸ä¼¼åº¦é˜ˆå€¼å½±å“
        similarity_results = [r for r in valid_results if 'similar' in r['name'] or 'baseline' in r['name']]
        if len(similarity_results) >= 2:
            f.write("### ç›¸ä¼¼åº¦é˜ˆå€¼å½±å“\n")
            for r in similarity_results:
                f.write(f"- **{r['name']}**: {r['keyframes_count']}ä¸ªå…³é”®å¸§, ç½®ä¿¡åº¦{r['avg_confidence']}\n")
            f.write("\n")
        
        # å»ºè®®
        f.write("## ğŸ’¡ ä½¿ç”¨å»ºè®®\n\n")
        f.write("1. **è¿½æ±‚æ•°é‡**: ä½¿ç”¨å…³é”®å¸§æ•°æœ€å¤šçš„é…ç½®\n")
        f.write("2. **è¿½æ±‚è´¨é‡**: ä½¿ç”¨å¹³å‡ç½®ä¿¡åº¦æœ€é«˜çš„é…ç½®\n") 
        f.write("3. **å¹³è¡¡è€ƒè™‘**: ä½¿ç”¨ç»¼åˆæ•ˆç‡æœ€ä½³çš„é…ç½®\n")
        f.write("4. **å­˜å‚¨è€ƒè™‘**: æ³¨æ„æ–‡ä»¶å¤§å°ï¼Œé€‰æ‹©é€‚åˆçš„é…ç½®\n\n")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ†æé•œå¤´æµ‹è¯•ç»“æœ")
    parser.add_argument("--test-dir", default=".", help="æµ‹è¯•ç»“æœç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)")
    parser.add_argument("--output", default="shot_analysis_report.md", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶")
    
    args = parser.parse_args()
    
    test_base_dir = Path(args.test_dir)
    
    # æŸ¥æ‰¾æ‰€æœ‰æµ‹è¯•ç›®å½•
    test_dirs = []
    for item in test_base_dir.iterdir():
        if item.is_dir() and (item.name.startswith("quick_test_") or item.name.startswith("shot_test_")):
            test_dirs.append(item)
    
    if not test_dirs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ç»“æœç›®å½•")
        print("ğŸ’¡ è¯·ç¡®ä¿è¿è¡Œäº† quick_shot_test.py æˆ– batch_shot_test.py")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(test_dirs)} ä¸ªæµ‹è¯•ç›®å½•")
    
    # åˆ†ææ¯ä¸ªç›®å½•
    results = []
    for test_dir in test_dirs:
        print(f"ğŸ” åˆ†æ: {test_dir.name}")
        result = analyze_directory(test_dir)
        results.append(result)
        print(f"   å…³é”®å¸§: {result['keyframes_count']}, é•œå¤´: {result['shots_covered']}")
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_comparison_report(results, args.output)
    
    # æ˜¾ç¤ºç®€è¦ç»“æœ
    valid_results = [r for r in results if r["keyframes_count"] > 0]
    if valid_results:
        valid_results.sort(key=lambda x: x["keyframes_count"], reverse=True)
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ’å (æŒ‰å…³é”®å¸§æ•°é‡):")
        for i, result in enumerate(valid_results[:5], 1):
            print(f"{i}. {result['name']}: {result['keyframes_count']}ä¸ªå…³é”®å¸§, "
                  f"{result['shots_covered']}ä¸ªé•œå¤´, ç½®ä¿¡åº¦{result['avg_confidence']}")
    
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}")


if __name__ == "__main__":
    main()
