#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬
ç›´æ¥è¿è¡Œå³å¯æµ‹è¯•è§†é¢‘å…³é”®å¸§æå–å™¨çš„æ‰€æœ‰åŠŸèƒ½
"""

import sys
import os
import time
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))


def main():
    """å¿«é€Ÿæµ‹è¯•ä¸»å‡½æ•°"""
    print("ğŸ¬ è§†é¢‘å…³é”®å¸§æå–å™¨ - å¿«é€Ÿæµ‹è¯•")
    print("=" * 50)

    # æ£€æŸ¥æµ‹è¯•è§†é¢‘
    video_path = "1.mp4"
    if not os.path.exists(video_path):
        print("âŒ æµ‹è¯•è§†é¢‘æ–‡ä»¶ 1.mp4 ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿ 1.mp4 æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹")
        return

    print(f"âœ… æ‰¾åˆ°æµ‹è¯•è§†é¢‘: {video_path}")

    try:
        # å¯¼å…¥æ¨¡å—
        print("\nğŸ“¦ å¯¼å…¥æ¨¡å—...")
        from video_keyframe_extractor import KeyFrameExtractor, Config
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")

        # åˆ›å»ºé…ç½®ï¼ˆä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼‰
        print("\nâš™ï¸ åˆ›å»ºé…ç½®...")
        config = Config(
            target_fps=5,           # ä½å¸§ç‡ï¼Œå¿«é€Ÿæµ‹è¯•
            use_transnet=True,      # ä½¿ç”¨PyTorchç‰ˆæœ¬çš„TransNetV2
            max_keyframes_per_shot=3,
            similarity_threshold=0.85,
            verbose=True
        )
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸï¼ˆåŒ…å«TransNetV2 PyTorchç‰ˆæœ¬ï¼‰")

        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = "test_output"
        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

        # å¼€å§‹æå–
        print("\nğŸš€ å¼€å§‹å…³é”®å¸§æå–...")
        start_time = time.time()

        with KeyFrameExtractor(config) as extractor:
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            model_info = extractor.get_model_info()
            print(f"ğŸ“Š æ¨¡å‹çŠ¶æ€:")
            print(f"  CLIPæ¨¡å‹: {'âœ… å·²åŠ è½½' if model_info['clip']['loaded'] else 'âŒ æœªåŠ è½½'}")
            print(f"  è®¾å¤‡: {model_info['clip']['device']}")
            print(f"  TransNetV2 PyTorch: {'âœ… å¯ç”¨å¹¶å·²åŠ è½½' if model_info['transnet']['available'] and model_info['transnet']['loaded'] else 'âŒ ä¸å¯ç”¨'}")

            if model_info['transnet']['available'] and model_info['transnet']['loaded']:
                print(f"  é•œå¤´æ£€æµ‹: ä½¿ç”¨TransNetV2 PyTorchç‰ˆæœ¬")
            else:
                print(f"  é•œå¤´æ£€æµ‹: å°†ä½¿ç”¨å¤‡ç”¨ç®—æ³•ï¼ˆç›´æ–¹å›¾å·®å¼‚ï¼‰")

            # æå–å…³é”®å¸§
            results = extractor.extract_keyframes(video_path, output_dir)

        end_time = time.time()
        processing_time = end_time - start_time

        # æ˜¾ç¤ºç»“æœ
        print("\nğŸ‰ æå–å®Œæˆï¼")
        print(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")

        if results:
            print(f"ğŸ“Š æå–ç»“æœ:")
            print(f"  å…³é”®å¸§æ•°é‡: {len(results)}")
            print(f"  è¾“å‡ºç›®å½•: {output_dir}")

            # æ˜¾ç¤ºå‰å‡ ä¸ªå…³é”®å¸§ä¿¡æ¯
            print(f"\nğŸ“‹ å…³é”®å¸§è¯¦æƒ…:")
            for i, result in enumerate(results[:5]):
                print(f"  {i+1}. {result['filename']}")
                print(f"     æ—¶é—´æˆ³: {result['timestamp']:.2f}s")
                print(f"     ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                print(f"     é•œå¤´ID: {result['shot_id']}")

            if len(results) > 5:
                print(f"  ... è¿˜æœ‰ {len(results) - 5} ä¸ªå…³é”®å¸§")

            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
            output_path = Path(output_dir)
            if output_path.exists():
                image_files = list(output_path.glob("*.jpg"))
                metadata_files = list(output_path.glob("*.json")) + list(output_path.glob("*.csv")) + list(output_path.glob("*.txt"))

                print(f"\nğŸ“‚ è¾“å‡ºæ–‡ä»¶:")
                print(f"  å›¾åƒæ–‡ä»¶: {len(image_files)} ä¸ª")
                print(f"  å…ƒæ•°æ®æ–‡ä»¶: {len(metadata_files)} ä¸ª")

                # æ˜¾ç¤ºä¸€äº›æ–‡ä»¶å
                if image_files:
                    print(f"  ç¤ºä¾‹å›¾åƒ: {image_files[0].name}")
                if metadata_files:
                    print(f"  å…ƒæ•°æ®: {[f.name for f in metadata_files]}")

            print(f"\nâœ… æµ‹è¯•æˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“ æŸ¥çœ‹ç»“æœ: {output_dir}")

        else:
            print("âŒ æœªæå–åˆ°å…³é”®å¸§")

    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥æ˜¯å¦å®‰è£…äº†æ‰€æœ‰ä¾èµ–:")
        print("  pip install -r requirements.txt")
        print("  pip install git+https://github.com/openai/CLIP.git")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")

        # æä¾›ä¸€äº›å¸¸è§é—®é¢˜çš„è§£å†³å»ºè®®
        if "CLIP" in str(e):
            print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("  1. å®‰è£…CLIP: pip install git+https://github.com/openai/CLIP.git")
            print("  2. å®‰è£…torch: pip install torch torchvision")

        elif "cv2" in str(e) or "opencv" in str(e):
            print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("  1. å®‰è£…OpenCV: pip install opencv-python")

        elif "sklearn" in str(e):
            print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("  1. å®‰è£…scikit-learn: pip install scikit-learn")

        elif "transnetv2" in str(e).lower():
            print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("  1. å®‰è£…TransNetV2 PyTorchç‰ˆæœ¬: pip install transnetv2-pytorch")
            print("  2. æˆ–è€…ç¦ç”¨TransNetV2: åœ¨é…ç½®ä¸­è®¾ç½® use_transnet=False")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ è„šæœ¬è¿è¡Œå¼‚å¸¸: {e}")

    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆ")

    # åœ¨Windowsä¸‹æš‚åœï¼Œè®©ç”¨æˆ·çœ‹åˆ°ç»“æœ
    if os.name == 'nt':
        input("\næŒ‰Enteré”®é€€å‡º...")